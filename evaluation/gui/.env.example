# OpenAI API
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=your_api_key_here

# Flask settings
SECRET_KEY=your_random_secret_key_here
FLASK_PORT=11001
FLASK_HOST=0.0.0.0

# Generation parameters
MAX_TOKENS=4096
TEMPERATURE=0
TOP_P=0

# Dataset configuration
DATA_DIR=scenario
MAIN_DATA_FILE=sample.json

# External inference server (vLLM)
EXTERNAL_API_URL=http://localhost:11002/generate
VLLM_PORT=11002
VLLM_MAX_TOKENS=4096
VLLM_MODEL_PATH=model/your_model_path_here
SCRIPT_PATH=vllm_server.py
